{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RulLu16/ML_practice/blob/master/%EC%8B%A4%EC%8A%B52.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhhvH7SHitl6",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial 2 - Logistic Regression by 손병호(soMLier)\n",
        "이번 실습에서는 Logistic Regression을 이용하여 간단한 데이터를 학습(train)하고 평가(test)하는 코드를 작성한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asyL9vYjV1OW",
        "colab_type": "text"
      },
      "source": [
        "logistic regression의 기초적인 내용과 관련해서는 다음의 링크를 참고하면 도움이 될 것이다.\n",
        "\n",
        "https://towardsdatascience.com/logistic-regression-explained-and-implemented-in-python-880955306060"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pcdCcKwT3_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxjW8VfOjI9X",
        "colab_type": "text"
      },
      "source": [
        "먼저 우리의 logistic regression 모델의 hyperparameter 들을 정의하자.\n",
        "* x_dim : feature 벡터의 차원수\n",
        "* lr : learning rate이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0NxPQGiZ-xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model settings\n",
        "x_dim = 2\n",
        "lr = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moAxfT49lKNy",
        "colab_type": "text"
      },
      "source": [
        "모델이 사용할 data set이 필요하다. 실습에서는 실제 데이터를 사용하지 않고 generate_toy_data() 함수를 이용하여 인위적으로 만들 것이다.\n",
        "\n",
        "data set은 여러개의 example들로 구성되고, 각 example은 다시 다음으로 구성된다.\n",
        "* x : feature vector (특징벡터 = 독립변수)\n",
        "* y : label (라벨 = 종속변수)\n",
        "\n",
        "여기서 x는 2차원 벡터이고, y는 스칼라이다.\n",
        "\n",
        "logistic regression은 기본적으로 binary classification 모델이므로, y는 0 혹은 1만을 가질 수 있다.\n",
        "\n",
        "주목해야할 점은, y의 값에 따라 x의 분포가 다르다는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZsjqEVockje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_toy_data(size):\n",
        "  '''\n",
        "    generates the toy data consisting of positive(50%) and negative(50%) examples\n",
        "      positive mean : [1,1]\n",
        "      negative mean : [-1,-1]\n",
        "    Arguments:\n",
        "      size -- number of positive examples(or negative examples)\n",
        "    Returns:\n",
        "      the tuple [feature vectors,labels]\n",
        "  '''\n",
        "  x0 = np.random.normal(size=2*size).reshape(-1, 2) - 1\n",
        "  x1 = np.random.normal(size=2*size).reshape(-1, 2) + 1.\n",
        "  return np.concatenate([x0, x1]), np.concatenate([np.zeros(size), np.ones(size)]).astype(np.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1plQxpMOmHlc",
        "colab_type": "text"
      },
      "source": [
        "generate_toy_data() 함수를 이용하여 만들어낸 데이터의 모습을 관찰해보자.\n",
        "\n",
        "generate_toy_data()로부터 생성된 X는 N개의 feature vector를 담고 있는 Matrix이고, y는 N개의 라벨을 담고 있는 vector 형태임을 확인할 수 있다.\n",
        "\n",
        "실제로, 이렇게 X와 y를 분리시켜 각각이 여러개의 example들을 담고 있게끔 데이터를 보관하는 방법이 널리 쓰인다. 이러한 데이터(example들의 모음)를 batch라고 부르며, 머신러닝의 학습은 대부분 batch 단위로 수행된다. (위 설명에서 batch size는 N이 된다)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li8upWBzdbSG",
        "colab_type": "code",
        "outputId": "4a801363-18e5-45f6-9873-bcdd59a5158a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# prepare the data\n",
        "train_X, train_y = generate_toy_data(30)\n",
        "test_X, test_y = generate_toy_data(10)\n",
        "\n",
        "print(test_X)\n",
        "print(test_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-9.89894942e-01 -8.50125743e-01]\n",
            " [-1.78620641e-03 -2.56553418e+00]\n",
            " [-1.43921257e+00 -7.74665067e-01]\n",
            " [-1.15191031e+00 -1.54143926e+00]\n",
            " [-7.24646808e-01 -1.85212128e+00]\n",
            " [-2.08625117e+00 -5.88638151e-01]\n",
            " [-5.51936904e-01 -1.32899340e+00]\n",
            " [-1.38620673e+00 -1.40358714e+00]\n",
            " [-7.35798017e-01 -1.58112008e+00]\n",
            " [-4.00731707e+00  1.26620436e-01]\n",
            " [ 1.12265146e+00 -1.77313033e-01]\n",
            " [ 2.03923441e+00  8.27440209e-01]\n",
            " [ 9.36326366e-01  1.48962437e+00]\n",
            " [ 1.42342262e+00  7.53052581e-01]\n",
            " [ 1.43579159e+00  1.06926948e+00]\n",
            " [ 1.44591306e+00  2.43861324e+00]\n",
            " [ 5.16466145e-01  1.58095396e+00]\n",
            " [ 1.24367023e+00  1.66067536e+00]\n",
            " [-1.46880704e-01 -8.45722334e-01]\n",
            " [ 2.59703016e+00  2.04130054e+00]]\n",
            "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuYImUQlq9Xr",
        "colab_type": "text"
      },
      "source": [
        "이제부터 logistic regression 모델을 학습 및 평가하는데 이용될 함수들을 정의할 것이다. 이 과정에서 input과 output 변수의 size에 주목하면 코드를 이해하는 것이 훨씬 수월해질 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NxrpHIfpWpi",
        "colab_type": "text"
      },
      "source": [
        "## sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV2LledmUGet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "  \"\"\"\n",
        "    computes the sigmoid elementwise\n",
        "    Arguments:\n",
        "      z -- vector of size [batch]\n",
        "    Returns:\n",
        "      sigmoid(z) -- vector of size [batch]\n",
        "  \"\"\"\n",
        "  return 1/(1+np.e**(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETBaR-6bpbtf",
        "colab_type": "text"
      },
      "source": [
        "## forward\n",
        "logistic regression이 데이터 X를 가지고 결과 y_hat을 계산하는 과정을 그대로 따른다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9dgbiMrWFJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(w,b,X):\n",
        "  \"\"\"\n",
        "    computes the logistic regression value for the given input\n",
        "    Arguments:\n",
        "      w -- weights of size [x_dim]\n",
        "      b -- bias, a scalar\n",
        "      X -- input data of size [batch, x_dim]\n",
        "    Returns:\n",
        "      sigmoid(z) -- probabilities of being in class 1 of size [batch]\n",
        "  \"\"\"\n",
        "  z = b + np.matmul(w,X.T)\n",
        "  return sigmoid(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVaQ-FYSpgpc",
        "colab_type": "text"
      },
      "source": [
        "## loss\n",
        "logistic regression의 오차함수이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5nj7ZsbUYyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(y,y_hat):\n",
        "  \"\"\"\n",
        "    computes the MSE loss\n",
        "    Arguments:\n",
        "      y -- the correct labels of size [batch]\n",
        "      y_hat -- the predictions of size [batch]\n",
        "    Returns:\n",
        "      the MSE loss w.r.t. y_hat\n",
        "  \"\"\"\n",
        "  return np.sum((y-y_hat)**2)/len(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke5UJpwgmZhk",
        "colab_type": "text"
      },
      "source": [
        "## optimize\n",
        "optimize() 함수는 우리의 logistic regression 모델을 이용하여 gradient descent를 \"한 스텝\" 진행시켜 준다. 이는 세부적으로 다음의 과정으로 진행된다.\n",
        "\n",
        "1) W,b의 그래디언트 계산\n",
        "\n",
        "2) W,b의 업데이트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGXKo5YXUIog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize(w,b,X,y,y_hat,lr=0.001):\n",
        "  \"\"\"\n",
        "    optimize one step\n",
        "    Arguments:\n",
        "      w -- weights of size [x_dim]\n",
        "      b -- bias, a scalar\n",
        "      X -- input data of size [batch, x_dim]\n",
        "      y -- labels of size [batch]\n",
        "      y_hat -- predictions of size [batch]\n",
        "      lr -- learning rate\n",
        "    Returns:\n",
        "      w -- optimized weights\n",
        "      b -- optimized bias\n",
        "  \"\"\"\n",
        "  bsize = len(y) # get batch size\n",
        "\n",
        "  # dw -- gradient of w\n",
        "  dw = np.zeros_like(w)\n",
        "  for i in range(len(dw)):\n",
        "    # TODO - calculate the derivative of L w.r.t w[i] (replace the 0)\n",
        "    dw[i] = 0\n",
        "\n",
        "  # db = get derivative at b\n",
        "  # TODO - calculate the derivative of L w.r.t b (replace the 0)\n",
        "  db = 0 \n",
        "\n",
        "  # take a step\n",
        "  w = w - lr * dw\n",
        "  b = b - lr * db\n",
        "  return w,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsskV_dhpum6",
        "colab_type": "text"
      },
      "source": [
        "## train\n",
        "앞에서 만든 optimize() 함수를 반복적으로 여러번 수행한다. 즉 gradient descent 여러 스텝을 수행한다. 그 결과로 우리는 최적화된 모델 W,b를 얻을 것이라고 기대할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW7UlCELU1re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(w,b,X,y,epoch,lr=0.001):\n",
        "  for _ in range(epoch):\n",
        "    y_hat = forward(w,b,X)\n",
        "    print(loss(y,y_hat))\n",
        "    w,b = optimize(w,b,X,y,y_hat,lr=lr)\n",
        "  return w,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjvEto0tpwE8",
        "colab_type": "text"
      },
      "source": [
        "## eval\n",
        "모델을 최종 평가하는 함수이다. 이때 위에서 정의한 loss를 이용하여 평가를 하지 않고, 진정한 의미의 성능 측도인 accuracy (correct/total)을 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n81janxXn4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(w,b,X,y):\n",
        "  \"\"\"\n",
        "  returns the accuracy of the learned model\n",
        "  \"\"\"\n",
        "  y_hat = forward(w,b,X)\n",
        "  res = [0 if i<0.5 else 1 for i in y_hat]\n",
        "  res = (res == y)\n",
        "  res = np.sum(res)/len(y)\n",
        "  print(\"accuracy : \"+str(res))\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V1g1XmZp5Ab",
        "colab_type": "text"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwlRi9GMdhVJ",
        "colab_type": "code",
        "outputId": "a667e145-4e33-46e5-e19e-759a77c15039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initialize model by 0\n",
        "weights = np.zeros(x_dim)\n",
        "bias = 0.\n",
        "print(weights, bias)\n",
        "eval(weights, bias, test_X, test_y)\n",
        "\n",
        "# train the model\n",
        "weights, bias = train(weights,bias,train_X,train_y,100,lr=0.2)\n",
        "print(weights, bias)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0.] 0.0\n",
            "accuracy : 0.5\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "0.25\n",
            "[0. 0.] 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WEwqq6td3Q4",
        "colab_type": "code",
        "outputId": "ee48cd21-f093-4653-f5e2-842ca7351a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# test the model\n",
        "eval(weights, bias, test_X, test_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}